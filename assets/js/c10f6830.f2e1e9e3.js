"use strict";(self.webpackChunkwebsite_2=self.webpackChunkwebsite_2||[]).push([[566],{5680:(e,t,a)=>{a.d(t,{xA:()=>s,yg:()=>y});var n=a(6540);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function l(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?l(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},l=Object.keys(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var p=n.createContext({}),g=function(e){var t=n.useContext(p),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},s=function(e){var t=g(e.components);return n.createElement(p.Provider,{value:t},e.children)},u="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,l=e.originalType,p=e.parentName,s=o(e,["components","mdxType","originalType","parentName"]),u=g(a),d=r,y=u["".concat(p,".").concat(d)]||u[d]||m[d]||l;return a?n.createElement(y,i(i({ref:t},s),{},{components:a})):n.createElement(y,i({ref:t},s))}));function y(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var l=a.length,i=new Array(l);i[0]=d;var o={};for(var p in t)hasOwnProperty.call(t,p)&&(o[p]=t[p]);o.originalType=e,o[u]="string"==typeof e?e:r,i[1]=o;for(var g=2;g<l;g++)i[g]=a[g];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}d.displayName="MDXCreateElement"},4644:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>i,default:()=>m,frontMatter:()=>l,metadata:()=>o,toc:()=>g});var n=a(8168),r=(a(6540),a(5680));const l={sidebar_position:1,slug:"/Pipelines/ImputationBeagle_Pipeline/README"},i="Imputation Overview",o={unversionedId:"Pipelines/ImputationBeagle_Pipeline/README",id:"Pipelines/ImputationBeagle_Pipeline/README",title:"Imputation Overview",description:"|                                                  Pipeline Version                                                  | Date Updated |        Documentation Author        |                             Questions or Feedback                              |",source:"@site/docs/Pipelines/ImputationBeagle_Pipeline/README.md",sourceDirName:"Pipelines/ImputationBeagle_Pipeline",slug:"/Pipelines/ImputationBeagle_Pipeline/README",permalink:"/warp/docs/Pipelines/ImputationBeagle_Pipeline/README",draft:!1,editUrl:"https://github.com/broadinstitute/warp/edit/develop/website/docs/Pipelines/ImputationBeagle_Pipeline/README.md",tags:[],version:"current",lastUpdatedBy:"jsotobroad",lastUpdatedAt:1759344150,formattedLastUpdatedAt:"Oct 1, 2025",sidebarPosition:1,frontMatter:{sidebar_position:1,slug:"/Pipelines/ImputationBeagle_Pipeline/README"},sidebar:"docsSidebar",previous:{title:"VCF Overview: Illumina Genotyping Array",permalink:"/warp/docs/Pipelines/Illumina_Genotyping_Arrays_Pipeline/Illumina_genotyping_array_spec"},next:{title:"Imputation Overview",permalink:"/warp/docs/Pipelines/Imputation_Pipeline/README"}},p={},g=[{value:"Introduction to the Array Imputation pipeline",id:"introduction-to-the-array-imputation-pipeline",level:2},{value:"Set-up",id:"set-up",level:2},{value:"Workflow installation and requirements",id:"workflow-installation-and-requirements",level:3},{value:"Input descriptions",id:"input-descriptions",level:3},{value:"Workflow tasks and tools",id:"workflow-tasks-and-tools",level:2},{value:"Workflow outputs",id:"workflow-outputs",level:2},{value:"Important notes",id:"important-notes",level:2},{value:"Citing the Imputation Pipeline",id:"citing-the-imputation-pipeline",level:2},{value:"Contact us",id:"contact-us",level:2},{value:"Licensing",id:"licensing",level:2}],s={toc:g},u="wrapper";function m(e){let{components:t,...l}=e;return(0,r.yg)(u,(0,n.A)({},s,l,{components:t,mdxType:"MDXLayout"}),(0,r.yg)("h1",{id:"imputation-overview"},"Imputation Overview"),(0,r.yg)("table",null,(0,r.yg)("thead",{parentName:"table"},(0,r.yg)("tr",{parentName:"thead"},(0,r.yg)("th",{parentName:"tr",align:"center"},"Pipeline Version"),(0,r.yg)("th",{parentName:"tr",align:"center"},"Date Updated"),(0,r.yg)("th",{parentName:"tr",align:"center"},"Documentation Author"),(0,r.yg)("th",{parentName:"tr",align:"center"},"Questions or Feedback"))),(0,r.yg)("tbody",{parentName:"table"},(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:"center"},(0,r.yg)("a",{parentName:"td",href:"https://github.com/broadinstitute/warp/releases?q=ImputationBeagle_v2.0.0&expanded=true"},"ImputationBeagle_v2.0.0")),(0,r.yg)("td",{parentName:"tr",align:"center"},"August, 2025"),(0,r.yg)("td",{parentName:"tr",align:"center"},"Terra Scientific Pipeline Services"),(0,r.yg)("td",{parentName:"tr",align:"center"},"Please ",(0,r.yg)("a",{parentName:"td",href:"https://github.com/broadinstitute/warp/issues"},"file an issue in WARP"),".")))),(0,r.yg)("h2",{id:"introduction-to-the-array-imputation-pipeline"},"Introduction to the Array Imputation pipeline"),(0,r.yg)("p",null,"The Array Imputation pipeline imputes missing genotypes from either a multi-sample VCF or an array of single-sample VCFs using a large genomic reference panel. It uses ",(0,r.yg)("a",{parentName:"p",href:"https://faculty.washington.edu/browning/beagle/beagle.html"},"Beagle")," as the imputation tool. Overall, the pipeline filters, phases, and performs imputation on a multi-sample VCF. It outputs the imputed VCF along with key imputation metrics."),(0,r.yg)("p",null,(0,r.yg)("img",{src:a(2472).A,width:"1862",height:"1422"})),(0,r.yg)("h2",{id:"set-up"},"Set-up"),(0,r.yg)("h3",{id:"workflow-installation-and-requirements"},"Workflow installation and requirements"),(0,r.yg)("p",null,"The ",(0,r.yg)("a",{parentName:"p",href:"https://github.com/broadinstitute/warp/blob/develop/pipelines/broad/arrays/imputation_beagle/ImputationBeagle.wdl"},"Array Imputation workflow")," is written in the Workflow Description Language (WDL) and can be deployed using a WDL-compatible execution engine like ",(0,r.yg)("a",{parentName:"p",href:"https://github.com/broadinstitute/cromwell"},"Cromwell"),", a GA4GH compliant, flexible workflow management system that supports multiple computing platforms.\nTo identify the latest workflow version and release notes, please see the Imputation workflow ",(0,r.yg)("a",{parentName:"p",href:"https://github.com/broadinstitute/warp/blob/develop/pipelines/broad/arrays/imputation_beagle/ImputationBeagle.changelog.md"},"changelog"),".\nThe latest release of the workflow, example data, and dependencies are available from the WARP releases page. To discover and search releases, use the WARP command-line tool ",(0,r.yg)("a",{parentName:"p",href:"https://github.com/broadinstitute/warp/tree/develop/wreleaser"},"Wreleaser"),"."),(0,r.yg)("p",null,"Using the Array Imputation pipeline\nThis pipeline is used by the ",(0,r.yg)("a",{parentName:"p",href:"http://allofus-anvil-imputation.terra.bio"},"All of Us + AnVIL Imputation Service"),". If you choose to use this service, you can impute your samples against the 515,000+ genomes in the All of Us + AnVIL reference panel, which can provide greater accuracy at more sites."),(0,r.yg)("admonition",{title:"Try the Imputation pipeline in Terra",type:"tip"},(0,r.yg)("p",{parentName:"admonition"},"You can alternatively run the pipeline with your own panel, using this ",(0,r.yg)("a",{parentName:"p",href:"https://github.com/broadinstitute/warp/blob/develop/pipelines/broad/arrays/imputation_beagle/ImputationBeagle.wdl"},"WDL"),".")),(0,r.yg)("h3",{id:"input-descriptions"},"Input descriptions"),(0,r.yg)("p",null,"The table below describes each of the Array Imputation pipeline inputs. The workflow requires a  multi-sample VCF. These samples must be from the same species and genotyping chip."),(0,r.yg)("p",null,"For examples of how to specify each input in a configuration file, as well as cloud locations for different example input files, see the ",(0,r.yg)("a",{parentName:"p",href:"https://github.com/broadinstitute/warp/blob/develop/pipelines/broad/arrays/imputation_beagle/test_inputs/Plumbing/NA12878_x10_hg38_arrays.json"},"example input configuration file (JSON)"),"."),(0,r.yg)("table",null,(0,r.yg)("thead",{parentName:"table"},(0,r.yg)("tr",{parentName:"thead"},(0,r.yg)("th",{parentName:"tr",align:null},"Input name"),(0,r.yg)("th",{parentName:"tr",align:null},"Description"),(0,r.yg)("th",{parentName:"tr",align:null},"Type"))),(0,r.yg)("tbody",{parentName:"table"},(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"ChunkLength"),(0,r.yg)("td",{parentName:"tr",align:null},"Size of chunks; default set to 25 MB."),(0,r.yg)("td",{parentName:"tr",align:null},"Int")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"chunkOverlaps"),(0,r.yg)("td",{parentName:"tr",align:null},"Padding adding to the beginning and end of each chunk to reduce edge effects; default set 5 MB."),(0,r.yg)("td",{parentName:"tr",align:null},"Int")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"sample_chunk_size"),(0,r.yg)("td",{parentName:"tr",align:null},"Number of samples to chunk by when processing (default: 1,000)"),(0,r.yg)("td",{parentName:"tr",align:null},"Int")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"multi_sample_vcf"),(0,r.yg)("td",{parentName:"tr",align:null},"Merged VCF containing multiple samples; can also use an array of individual VCFs."),(0,r.yg)("td",{parentName:"tr",align:null},"File")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"ref_dict"),(0,r.yg)("td",{parentName:"tr",align:null},"Reference dictionary."),(0,r.yg)("td",{parentName:"tr",align:null},"File")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"contigs"),(0,r.yg)("td",{parentName:"tr",align:null},"Array of allowed contigs/chromosomes to process"),(0,r.yg)("td",{parentName:"tr",align:null},"Array of strings")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"reference_panel_path_prefix"),(0,r.yg)("td",{parentName:"tr",align:null},"Path to the cloud storage containing the reference panel files for all contigs."),(0,r.yg)("td",{parentName:"tr",align:null},"String")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"genetics_maps_path"),(0,r.yg)("td",{parentName:"tr",align:null},"Path to the cloud storage containing the genetic map files for all contigs."),(0,r.yg)("td",{parentName:"tr",align:null},"File")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"output_callset_name"),(0,r.yg)("td",{parentName:"tr",align:null},"Output callset name."),(0,r.yg)("td",{parentName:"tr",align:null},"String")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"bcf_suffix"),(0,r.yg)("td",{parentName:"tr",align:null},"File extension used for the BED in the reference panel."),(0,r.yg)("td",{parentName:"tr",align:null},"String")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"bref3_suffix"),(0,r.yg)("td",{parentName:"tr",align:null},"File extension used for the BREF3 in the reference panel."),(0,r.yg)("td",{parentName:"tr",align:null},"String")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"error_count_override"),(0,r.yg)("td",{parentName:"tr",align:null},"Override for error check on chunk qc (set to 0 for workflow to continue no matter how many errors exist)"),(0,r.yg)("td",{parentName:"tr",align:null},"Int")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"min_dr2_for_inclusion"),(0,r.yg)("td",{parentName:"tr",align:null},"Min value of DR2 to include in final output (default: 0.0)"),(0,r.yg)("td",{parentName:"tr",align:null})))),(0,r.yg)("h2",{id:"workflow-tasks-and-tools"},"Workflow tasks and tools"),(0,r.yg)("p",null,"The ",(0,r.yg)("a",{parentName:"p",href:"https://github.com/broadinstitute/warp/blob/develop/pipelines/broad/arrays/imputation_beagle/ImputationBeagle.wdl"},"Array Imputation workflow")," imports a series of tasks from the ImputationTasks WDL and ImputationBeagleTasks WDL, which are hosted in the Broad ",(0,r.yg)("a",{parentName:"p",href:"https://github.com/broadinstitute/warp/tree/develop/tasks/broad"},"tasks library"),". The table below describes each workflow task, including the task name, tools, relevant software and non-default parameters. "),(0,r.yg)("table",null,(0,r.yg)("thead",{parentName:"table"},(0,r.yg)("tr",{parentName:"thead"},(0,r.yg)("th",{parentName:"tr",align:null},"Task name (alias) in WDL"),(0,r.yg)("th",{parentName:"tr",align:null},"Tool"),(0,r.yg)("th",{parentName:"tr",align:null},"Software"),(0,r.yg)("th",{parentName:"tr",align:null},"Description"))),(0,r.yg)("tbody",{parentName:"table"},(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"CountSamples"),(0,r.yg)("td",{parentName:"tr",align:null},"query"),(0,r.yg)("td",{parentName:"tr",align:null},"bcftools"),(0,r.yg)("td",{parentName:"tr",align:null},"Uses the merged input VCF file to count the number of samples and output a TXT file containing the count.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"CreateVcfIndex"),(0,r.yg)("td",{parentName:"tr",align:null},"index"),(0,r.yg)("td",{parentName:"tr",align:null},"bcftools"),(0,r.yg)("td",{parentName:"tr",align:null},"Creates index of input multisample vcf")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"CalculateContigsToProcess"),(0,r.yg)("td",{parentName:"tr",align:null},"Determine which contigs will be processed by the workflow"),(0,r.yg)("td",{parentName:"tr",align:null},"multi_sample_vcf, contigs"),(0,r.yg)("td",{parentName:"tr",align:null},"Extracts contigs from input VCF and filters by allowed contigs")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"CalculateChromsomeLength"),(0,r.yg)("td",{parentName:"tr",align:null},"grep"),(0,r.yg)("td",{parentName:"tr",align:null},"bash"),(0,r.yg)("td",{parentName:"tr",align:null},"Reads chromosome lengths from the reference dictionary and uses these to generate chunk intervals for the GenerateChunk task.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"GenerateChunk"),(0,r.yg)("td",{parentName:"tr",align:null},"SelectVariants"),(0,r.yg)("td",{parentName:"tr",align:null},"GATK"),(0,r.yg)("td",{parentName:"tr",align:null},"Performs site filtering by selecting SNPs only and excluding InDels, removing duplicate sites from the VCF, selecting biallelic variants, excluding symbolic/mixed variants, and removing sites with a maximum fraction of samples with no-call genotypes greater than 0.1. Also subsets to only a specified chunk of the genome.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"CountVariantsInChunks"),(0,r.yg)("td",{parentName:"tr",align:null},"CountVariants, intersect"),(0,r.yg)("td",{parentName:"tr",align:null},"GATK, bedtools"),(0,r.yg)("td",{parentName:"tr",align:null},"Counts variants in the filtered VCF file; Returns the number of chunks in the array and in the reference file.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"CheckChunks"),(0,r.yg)("td",{parentName:"tr",align:null},"convert"),(0,r.yg)("td",{parentName:"tr",align:null},"bcftools"),(0,r.yg)("td",{parentName:"tr",align:null},"Confirms that there are no chunks where less than 3 sites or less than 50% of the sites in the array are also in the reference panel; if valid, creates a new VCF output.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"StoreChunksInfo"),(0,r.yg)("td",{parentName:"tr",align:null}),(0,r.yg)("td",{parentName:"tr",align:null},"R"),(0,r.yg)("td",{parentName:"tr",align:null},"Gathers all results from CheckChunks")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"ErrorWithMessageIfErrorCountNotZero"),(0,r.yg)("td",{parentName:"tr",align:null}),(0,r.yg)("td",{parentName:"tr",align:null},"bash"),(0,r.yg)("td",{parentName:"tr",align:null},"Fails workflow if any chunks fail qc check.  Can be overridden with error_count_override input")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"SelectSamplesWithCut"),(0,r.yg)("td",{parentName:"tr",align:null},"cut"),(0,r.yg)("td",{parentName:"tr",align:null},"bash"),(0,r.yg)("td",{parentName:"tr",align:null},"Chunks vcf by sample_chunk_size if more than sample_chunk_size samples exist in input vcf")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"Phase"),(0,r.yg)("td",{parentName:"tr",align:null}),(0,r.yg)("td",{parentName:"tr",align:null},"Beagle"),(0,r.yg)("td",{parentName:"tr",align:null},"Performs phasing on the filtered, validated VCF")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"Impute"),(0,r.yg)("td",{parentName:"tr",align:null}),(0,r.yg)("td",{parentName:"tr",align:null},"Beagle"),(0,r.yg)("td",{parentName:"tr",align:null},"Performs imputation on the prephased VCF;")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"LocalizeAndSubsetVcfToRegion"),(0,r.yg)("td",{parentName:"tr",align:null},"SelectVariants"),(0,r.yg)("td",{parentName:"tr",align:null},"GATK"),(0,r.yg)("td",{parentName:"tr",align:null},"Remove padding from imputed vcf")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"QuerySampleChunkedVcfForReannotation"),(0,r.yg)("td",{parentName:"tr",align:null},"query"),(0,r.yg)("td",{parentName:"tr",align:null},"bcftools"),(0,r.yg)("td",{parentName:"tr",align:null},"Query DS, AP1, AP2 from sample chunked VCFs to be used when merging samples together")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"RemoveAPAnnotations"),(0,r.yg)("td",{parentName:"tr",align:null},"annotate"),(0,r.yg)("td",{parentName:"tr",align:null},"bcftools"),(0,r.yg)("td",{parentName:"tr",align:null},"Remove AP1, AP2 annotations to reduce file size now that they\u2019re no longer needed")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"RecalculateDR2AndAFChunked"),(0,r.yg)("td",{parentName:"tr",align:null}),(0,r.yg)("td",{parentName:"tr",align:null},"python"),(0,r.yg)("td",{parentName:"tr",align:null},"Used query output to summarize DS, AP1, AP2 values")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"MergeSampleChunksVcfsWithPaste"),(0,r.yg)("td",{parentName:"tr",align:null},"Paste, view"),(0,r.yg)("td",{parentName:"tr",align:null},"Bash, bcftools"),(0,r.yg)("td",{parentName:"tr",align:null},"Merge sample chunked VCFs")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"IndexMergedSampleChunksVcfs"),(0,r.yg)("td",{parentName:"tr",align:null},"index"),(0,r.yg)("td",{parentName:"tr",align:null},"bcftools"),(0,r.yg)("td",{parentName:"tr",align:null},"Creates index for sample chunk merged VCF")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"AggregateChunkedDR2AndAF"),(0,r.yg)("td",{parentName:"tr",align:null}),(0,r.yg)("td",{parentName:"tr",align:null},"python"),(0,r.yg)("td",{parentName:"tr",align:null},"Take summarized DS, AP1, AP2 data and calculate AF and DR2")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"ReannotateDR2AndAF"),(0,r.yg)("td",{parentName:"tr",align:null},"annotate"),(0,r.yg)("td",{parentName:"tr",align:null},"bcftools"),(0,r.yg)("td",{parentName:"tr",align:null},"Reannotate DR2 and AF for sample chunk merged vcf")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"FilterVcfByDR2"),(0,r.yg)("td",{parentName:"tr",align:null},"Filter variants by DR2 threshold"),(0,r.yg)("td",{parentName:"tr",align:null},"imputed VCF, min_dr2_for_inclusion"),(0,r.yg)("td",{parentName:"tr",align:null},"Removes variants below provided min_dr2_for_inclusion value")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"UpdateHeader"),(0,r.yg)("td",{parentName:"tr",align:null},"UpdateVCFSequenceDictionary"),(0,r.yg)("td",{parentName:"tr",align:null},"GATK"),(0,r.yg)("td",{parentName:"tr",align:null},"Updates the header of the imputed VCF; adds contig lengths")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"GatherVcfsNoIndex"),(0,r.yg)("td",{parentName:"tr",align:null},"GatherVCFs"),(0,r.yg)("td",{parentName:"tr",align:null},"GATK"),(0,r.yg)("td",{parentName:"tr",align:null},"Gathers the array of imputed VCFs and merges them into one VCF output.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"CreateIndexForGatheredVcf"),(0,r.yg)("td",{parentName:"tr",align:null},"index"),(0,r.yg)("td",{parentName:"tr",align:null},"bcftools"),(0,r.yg)("td",{parentName:"tr",align:null},"Creates index for final output vcf")))),(0,r.yg)("h2",{id:"workflow-outputs"},"Workflow outputs"),(0,r.yg)("p",null,"The table below summarizes the workflow outputs. If running the workflow on Cromwell, these outputs are found in the task execution directory."),(0,r.yg)("table",null,(0,r.yg)("thead",{parentName:"table"},(0,r.yg)("tr",{parentName:"thead"},(0,r.yg)("th",{parentName:"tr",align:null},"Output name"),(0,r.yg)("th",{parentName:"tr",align:null},"Description"),(0,r.yg)("th",{parentName:"tr",align:null},"Type"))),(0,r.yg)("tbody",{parentName:"table"},(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"imputed_multisample_vcf"),(0,r.yg)("td",{parentName:"tr",align:null},"VCF from the CreateIndexForGatheredVcf task; contains imputed variants as well as missing variants from the input VCF."),(0,r.yg)("td",{parentName:"tr",align:null},"VCF")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"imputed_multisample_vcf_index"),(0,r.yg)("td",{parentName:"tr",align:null},"Index file for VCF from the CreateIndexForGatheredVcf task."),(0,r.yg)("td",{parentName:"tr",align:null},"Index")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"chunks_info"),(0,r.yg)("td",{parentName:"tr",align:null},"TSV from StoreChunksInfo task; contains the chunk intervals as well as the number of variants in the array."),(0,r.yg)("td",{parentName:"tr",align:null},"TSV")))),(0,r.yg)("h2",{id:"important-notes"},"Important notes"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"Runtime parameters are optimized for Broad's Google Cloud Platform implementation.")),(0,r.yg)("h2",{id:"citing-the-imputation-pipeline"},"Citing the Imputation Pipeline"),(0,r.yg)("p",null,"If you use the Imputation Pipeline in your research, please consider citing our preprint:"),(0,r.yg)("p",null,"Degatano, K.; Awdeh, A.; Dingman, W.; Grant, G.; Khajouei, F.; Kiernan, E.; Konwar, K.; Mathews, K.; Palis, K.; Petrillo, N.; Van der Auwera, G.; Wang, C.; Way, J.; Pipelines, W. WDL Analysis Research Pipelines: Cloud-Optimized Workflows for Biological Data Processing and Reproducible Analysis. Preprints 2024, 2024012131. ",(0,r.yg)("a",{parentName:"p",href:"https://doi.org/10.20944/preprints202401.2131.v1"},"https://doi.org/10.20944/preprints202401.2131.v1")),(0,r.yg)("h2",{id:"contact-us"},"Contact us"),(0,r.yg)("p",null,"Help us make our tools better by ",(0,r.yg)("a",{parentName:"p",href:"https://github.com/broadinstitute/warp/issues"},"filing an issue in WARP"),"; we welcome pipeline-related suggestions or questions."),(0,r.yg)("h2",{id:"licensing"},"Licensing"),(0,r.yg)("p",null,"Copyright Broad Institute, 2020 | BSD-3"),(0,r.yg)("p",null,"The workflow script is released under the ",(0,r.yg)("strong",{parentName:"p"},"WDL open source code license (BSD-3)")," (full license text at ",(0,r.yg)("a",{parentName:"p",href:"https://github.com/broadinstitute/warp/blob/master/LICENSE"},"https://github.com/broadinstitute/warp/blob/master/LICENSE"),"). However, please note that the programs it calls may be subject to different licenses. Users are responsible for checking that they are authorized to run all programs before running this script."),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("a",{parentName:"li",href:"https://github.com/broadinstitute/gatk/blob/master/LICENSE.TXT"},"GATK")),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("a",{parentName:"li",href:"https://github.com/broadinstitute/picard/blob/master/LICENSE.txt"},"Picard")),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("a",{parentName:"li",href:"https://faculty.washington.edu/browning/beagle/beagle.html"},"Beagle")),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("a",{parentName:"li",href:"https://github.com/samtools/bcftools/blob/develop/LICENSE"},"bcftools")),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("a",{parentName:"li",href:"http://vcftools.sourceforge.net/license.html"},"vcftools"))))}m.isMDXComponent=!0},2472:(e,t,a)=>{a.d(t,{A:()=>n});const n=a.p+"assets/images/pipeline-513207ca464abdc89b555e79da1c58e7.png"}}]);