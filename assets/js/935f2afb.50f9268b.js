"use strict";(self.webpackChunkwebsite_2=self.webpackChunkwebsite_2||[]).push([[8581],{5610:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"docsSidebar":[{"type":"link","label":"Welcome to WARP","href":"/warp/docs/get-started","docId":"get-started"},{"type":"category","label":"About WARP","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Best Practices for Building Data Processing Pipelines","href":"/warp/docs/About_WARP/BestPractices","docId":"About_WARP/BestPractices"},{"type":"link","label":"Pipeline Requirements","href":"/warp/docs/About_WARP/PipelineRequirements","docId":"About_WARP/PipelineRequirements"},{"type":"link","label":"Testing Pipelines","href":"/warp/docs/About_WARP/TestingPipelines","docId":"About_WARP/TestingPipelines"},{"type":"link","label":"Version and Release Pipelines","href":"/warp/docs/About_WARP/VersionAndReleasePipelines","docId":"About_WARP/VersionAndReleasePipelines"},{"type":"link","label":"Forking WARP","href":"/warp/docs/About_WARP/ForkingWARP","docId":"About_WARP/ForkingWARP"}]},{"type":"category","label":"WARP Pipelines","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"ATAC","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"ATAC Count Matrix Overview","href":"/warp/docs/Pipelines/ATAC/count-matrix-overview","docId":"Pipelines/ATAC/count-matrix-overview"},{"type":"link","label":"ATAC Library Metrics Overview","href":"/warp/docs/Pipelines/ATAC/library-metrics","docId":"Pipelines/ATAC/library-metrics"},{"type":"link","label":"ATAC v2.3.1 Methods","href":"/warp/docs/Pipelines/ATAC/atac.methods","docId":"Pipelines/ATAC/atac.methods"}],"href":"/warp/docs/Pipelines/ATAC/README"},{"type":"category","label":"BuildIndices","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Reference Species","href":"/warp/docs/Pipelines/BuildIndices_Pipeline/ReferencesSpecies","docId":"Pipelines/BuildIndices_Pipeline/ReferencesSpecies"}],"href":"/warp/docs/Pipelines/BuildIndices_Pipeline/README"},{"type":"category","label":"Exome Germline Single Sample","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Exome Germline Single Sample v3.1.19 Methods","href":"/warp/docs/Pipelines/Exome_Germline_Single_Sample_Pipeline/exome.methods","docId":"Pipelines/Exome_Germline_Single_Sample_Pipeline/exome.methods"}],"href":"/warp/docs/Pipelines/Exome_Germline_Single_Sample_Pipeline/README"},{"type":"category","label":"Illumina Genotyping Array","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"VCF Overview: Illumina Genotyping Array","href":"/warp/docs/Pipelines/Illumina_Genotyping_Arrays_Pipeline/Illumina_genotyping_array_spec","docId":"Pipelines/Illumina_Genotyping_Arrays_Pipeline/Illumina_genotyping_array_spec"}],"href":"/warp/docs/Pipelines/Illumina_Genotyping_Arrays_Pipeline/README"},{"type":"link","label":"ImputationBeagle","href":"/warp/docs/Pipelines/ImputationBeagle_Pipeline/README","docId":"Pipelines/ImputationBeagle_Pipeline/README"},{"type":"category","label":"Imputation","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Creating the Imputation Pipeline\'s Modified 1000 Genomes Reference","href":"/warp/docs/Pipelines/Imputation_Pipeline/references_overview","docId":"Pipelines/Imputation_Pipeline/references_overview"}],"href":"/warp/docs/Pipelines/Imputation_Pipeline/README"},{"type":"link","label":"JointGenotyping","href":"/warp/docs/Pipelines/JointGenotyping_Pipeline/README","docId":"Pipelines/JointGenotyping/README"},{"type":"link","label":"Multiome scATAC and GEX","href":"/warp/docs/Pipelines/Multiome_Pipeline/README","docId":"Pipelines/Multiome_Pipeline/README"},{"type":"category","label":"Optimus","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Optimus v7.8.1 Methods","href":"/warp/docs/Pipelines/Optimus_Pipeline/optimus.methods","docId":"Pipelines/Optimus_Pipeline/optimus.methods"},{"type":"link","label":"What tags are included in an Optimus BAM file?","href":"/warp/docs/Pipelines/Optimus_Pipeline/Bam_tags","docId":"Pipelines/Optimus_Pipeline/Bam_tags"},{"type":"link","label":"Optimus Count Matrix Overview","href":"/warp/docs/Pipelines/Optimus_Pipeline/Loom_schema","docId":"Pipelines/Optimus_Pipeline/Loom_schema"},{"type":"link","label":"Optimus Library-level metrics","href":"/warp/docs/Pipelines/Optimus_Pipeline/Library-metrics","docId":"Pipelines/Optimus_Pipeline/Library-metrics"},{"type":"link","label":"Consortia Data Processing","href":"/warp/docs/Pipelines/Optimus_Pipeline/consortia-processing","docId":"Pipelines/Optimus_Pipeline/consortia-processing"},{"type":"link","label":"STAR Aligner Metrics","href":"/warp/docs/Pipelines/Optimus_Pipeline/starsolo-metrics","docId":"Pipelines/Optimus_Pipeline/starsolo-metrics"}],"href":"/warp/docs/Pipelines/Optimus_Pipeline/README"},{"type":"link","label":"Paired-Tag","href":"/warp/docs/Pipelines/PairedTag_Pipeline/README","docId":"Pipelines/PairedTag_Pipeline/README"},{"type":"category","label":"RNA with UMIs","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"RNA with UMIs v1.0.16 Methods","href":"/warp/docs/Pipelines/RNA_with_UMIs_Pipeline/rna-with-umis.methods","docId":"Pipelines/RNA_with_UMIs_Pipeline/rna-with-umis.methods"}],"href":"/warp/docs/Pipelines/RNA_with_UMIs_Pipeline/README"},{"type":"category","label":"Slide-seq","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Slide-seq Count Matrix Overview","href":"/warp/docs/Pipelines/SlideSeq_Pipeline/count-matrix-overview","docId":"Pipelines/SlideSeq_Pipeline/count-matrix-overview"}],"href":"/warp/docs/Pipelines/SlideSeq_Pipeline/README"},{"type":"link","label":"Slide-tags","href":"/warp/docs/Pipelines/SlideTags_Pipeline/README","docId":"Pipelines/SlideTags_Pipeline/README"},{"type":"category","label":"Smart-seq2 Single Nucleus Multi-Sample","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Smart-seq2 Single Nucleus Multi-Sample v1.3.4 Publication Methods","href":"/warp/docs/Pipelines/Smart-seq2_Single_Nucleus_Multi_Sample_Pipeline/multi_snss2.methods","docId":"Pipelines/Smart-seq2_Single_Nucleus_Multi_Sample_Pipeline/multi_snss2.methods"},{"type":"link","label":"Smart-seq2 Single Nucleus Multi-Sample Count Matrix Overview","href":"/warp/docs/Pipelines/Smart-seq2_Single_Nucleus_Multi_Sample_Pipeline/count-matrix-overview","docId":"Pipelines/Smart-seq2_Single_Nucleus_Multi_Sample_Pipeline/count-matrix-overview"},{"type":"link","label":"Consortia Data Processing","href":"/warp/docs/Pipelines/Smart-seq2_Single_Nucleus_Multi_Sample_Pipeline/consortia-processing","docId":"Pipelines/Smart-seq2_Single_Nucleus_Multi_Sample_Pipeline/consortia-processing"}],"href":"/warp/docs/Pipelines/Smart-seq2_Single_Nucleus_Multi_Sample_Pipeline/README"},{"type":"category","label":"Single Nucleus Methyl-Seq and Chromatin Capture","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"snm3C Mapping Summary Metrics Overview","href":"/warp/docs/Pipelines/snM3C/summary_metrics","docId":"Pipelines/snM3C/summary_metrics"},{"type":"link","label":"snM3C v4.0.1 Methods","href":"/warp/docs/Pipelines/snM3C/snm3c.methods","docId":"Pipelines/snM3C/snm3c.methods"}],"href":"/warp/docs/Pipelines/snm3C/README"},{"type":"link","label":"Ultima Genomics Whole Genome Germline","href":"/warp/docs/Pipelines/Ultima_Genomics_Whole_Genome_Germline_Pipeline/README","docId":"Pipelines/Ultima_Genomics_Whole_Genome_Germline_Pipeline/README"},{"type":"category","label":"Whole Genome Germline Single Sample","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Whole Genome Germline Single Sample v3.1.20 Methods (Default workflow)","href":"/warp/docs/Pipelines/Whole_Genome_Germline_Single_Sample_Pipeline/wgs.methods","docId":"Pipelines/Whole_Genome_Germline_Single_Sample_Pipeline/wgs.methods"}],"href":"/warp/docs/Pipelines/Whole_Genome_Germline_Single_Sample_Pipeline/README"}]},{"type":"category","label":"WDL Best Practices","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"WDL cost optimization: Tips and tricks when working with Google Cloud in Terra","href":"/warp/docs/Best_practices/GC_cost_optimization","docId":"Best_practices/GC_cost_optimization"},{"type":"link","label":"Autosizing disk for Google Cloud","href":"/warp/docs/Best_practices/autosize","docId":"Best_practices/autosize"},{"type":"link","label":"Setting default values","href":"/warp/docs/Best_practices/setting_defaults","docId":"Best_practices/setting_defaults"},{"type":"link","label":"Reusing WDL code","href":"/warp/docs/Best_practices/reusing_code","docId":"Best_practices/reusing_code"},{"type":"link","label":"WDL formatting tips","href":"/warp/docs/Best_practices/suggested_formats","docId":"Best_practices/suggested_formats"},{"type":"link","label":"Task execution - tips for using the WDL task command section","href":"/warp/docs/Best_practices/task_execution","docId":"Best_practices/task_execution"}]},{"type":"category","label":"Deprecated Pipelines","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"CEMBA","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"CEMBA_v1.1.6 Publication Methods","href":"/warp/docs/Deprecated_Pipelines/CEMBA_MethylC_Seq_Pipeline/CEMBA.methods","docId":"Deprecated_Pipelines/CEMBA_MethylC_Seq_Pipeline/CEMBA.methods"}],"href":"/warp/docs/Pipelines/CEMBA_MethylC_Seq_Pipeline/README"},{"type":"link","label":"GDC Whole Genome Somatic Single Sample","href":"/warp/docs/Pipelines/Genomic_Data_Commons_Whole_Genome_Somatic/README","docId":"Deprecated_Pipelines/Genomic_Data_Commons_Whole_Genome_Somatic/README"},{"type":"category","label":"Single Cell ATAC","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"scATAC v1.3.2 Methods","href":"/warp/docs/Deprecated_Pipelines/Single_Cell_ATAC_Seq_Pipeline/scatac.methods","docId":"Deprecated_Pipelines/Single_Cell_ATAC_Seq_Pipeline/scatac.methods"}],"href":"/warp/docs/Pipelines/Single_Cell_ATAC_Seq_Pipeline/README"},{"type":"category","label":"Smart-seq2 Multi-Sample","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Smart-seq2 Multi-Sample v2.2.21 Publication Methods","href":"/warp/docs/Deprecated_Pipelines/Smart-seq2_Multi_Sample_Pipeline/smart-seq2.methods","docId":"Deprecated_Pipelines/Smart-seq2_Multi_Sample_Pipeline/smart-seq2.methods"},{"type":"link","label":"What\'s in the Smart-seq2 Multi Sample Pipeline Loom File?","href":"/warp/docs/Deprecated_Pipelines/Smart-seq2_Multi_Sample_Pipeline/Loom_schema","docId":"Deprecated_Pipelines/Smart-seq2_Multi_Sample_Pipeline/Loom_schema"}],"href":"/warp/docs/Pipelines/Smart-seq2_Multi_Sample_Pipeline/README"},{"type":"category","label":"Smart-seq2 Single Sample","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"What\'s in the Smart-seq2 Single Sample Pipeline Loom File?","href":"/warp/docs/Deprecated_Pipelines/Smart-seq2_Single_Sample_Pipeline/Loom_schema","docId":"Deprecated_Pipelines/Smart-seq2_Single_Sample_Pipeline/Loom_schema"}],"href":"/warp/docs/Pipelines/Smart-seq2_Single_Sample_Pipeline/README"}]},{"type":"category","label":"Contribution Guide","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Contribute to WARP","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Changelog Style Guide Overview","href":"/warp/docs/contribution/contribute_to_warp/changelog_style","docId":"contribution/contribute_to_warp/changelog_style"},{"type":"link","label":"WDL Task Runtime Style Guide Overview","href":"/warp/docs/contribution/contribute_to_warp/wdl_task_runtime_style","docId":"contribution/contribute_to_warp/wdl_task_runtime_style"},{"type":"link","label":"Contributing to Existing Pipelines","href":"/warp/docs/contribution/contribute_to_warp/contribution-guidelines","docId":"contribution/contribute_to_warp/contribution-guidelines"},{"type":"link","label":"Example Contribution","href":"/warp/docs/contribution/contribute_to_warp/contribution-tutorial","docId":"contribution/contribute_to_warp/contribution-tutorial"}]},{"type":"category","label":"Contribute to WARP Documentation","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"WARP Documentation Maintenance Guide","href":"/warp/docs/contribution/contribute_to_warp_docs/docsite_maintenance","docId":"contribution/contribute_to_warp_docs/docsite_maintenance"},{"type":"link","label":"Documentation Style Guide","href":"/warp/docs/contribution/contribute_to_warp_docs/doc_style","docId":"contribution/contribute_to_warp_docs/doc_style"}]}],"href":"/warp/docs/contribution/README"}]},"docs":{"About_WARP/BestPractices":{"id":"About_WARP/BestPractices","title":"Best Practices for Building Data Processing Pipelines","description":"WARP pipeline development is guided by the best practices detailed below. We describe each of these best practices to give insight as to why they are important and we provide examples to give you a sense of how to apply them.","sidebar":"docsSidebar"},"About_WARP/ForkingWARP":{"id":"About_WARP/ForkingWARP","title":"Forking WARP","description":"The best way to make pipelines your own is to fork WARP. Forking is also a great way to create new pipelines or to suggest improvements to existing pipelines. Here we take you through all the steps needed to fork WARP using Github, and what the best options are for how to deploy your forked code to run in the cloud.","sidebar":"docsSidebar"},"About_WARP/PipelineRequirements":{"id":"About_WARP/PipelineRequirements","title":"Pipeline Requirements","description":"All released WARP pipelines should meet the following criteria:","sidebar":"docsSidebar"},"About_WARP/TestingPipelines":{"id":"About_WARP/TestingPipelines","title":"Testing Pipelines","description":"WARP pipelines have accompanying automated tests that run on each Pull Request (PR). These tests compare validated outputs to the new PR outputs. For any changes in code shared between pipelines, the tests also confirm which pipelines could be affected and ensure that the PR makes no unexpected changes to the affected pipelines.","sidebar":"docsSidebar"},"About_WARP/VersionAndReleasePipelines":{"id":"About_WARP/VersionAndReleasePipelines","title":"Version and Release Pipelines","description":"WARP Pipelines are versioned semantically, allowing you to determine how and when your data was created (provenance). This promotes compatibility across datasets and ensures that analyses can be reproduced by the global scientific community. Semantic version numbers (written as major.minor.patch) are human readable and give immediate insight into the compatibility of pipeline outputs (see the Versioning Guidelines below).","sidebar":"docsSidebar"},"Best_practices/autosize":{"id":"Best_practices/autosize","title":"Autosizing disk for Google Cloud","description":"When writing a WDL workflow, you have the option to customize your runtime environments, like the size of a virtual computer\'s disk, memory, and the type of disk you want to use. While you can hardcode standard values for these runtime parameters, there are times when dynamically calculating your parameters based on file sizes could be useful, like when you\u2019re working with large data sets. If you find yourself having to modify your runtime values often, it\u2019s probably beneficial to use some autosizing features.","sidebar":"docsSidebar"},"Best_practices/GC_cost_optimization":{"id":"Best_practices/GC_cost_optimization","title":"WDL cost optimization: Tips and tricks when working with Google Cloud in Terra","description":"Reducing the cost of your WDL workflow is always a priority. Below, the Broad Institute\u2019s Pipelines team provides some tips and tricks for optimizing workflow costs for runs using Google Cloud virtual machines (VM) from the bioinformatics platform, Terra.","sidebar":"docsSidebar"},"Best_practices/reusing_code":{"id":"Best_practices/reusing_code","title":"Reusing WDL code","description":"Whether you\u2019re setting up workflows for future reusability or trying to reuse someone else\u2019s code, the Broad Pipeline Development team has a few tips and tricks to consider for your use case.","sidebar":"docsSidebar"},"Best_practices/setting_defaults":{"id":"Best_practices/setting_defaults","title":"Setting default values","description":"In WDL, default values are those that allow your workflow to run in the absence of a user-defined attribute. These include primary inputs that you\u2019ve hardcoded to a value, but they can also include inputs that are assigned to dynamically calculated functions (like autosizing functions for setting runtime parameters). If you\u2019re wondering whether a parameter has a default value or not, just ask yourself, \u201cWill the workflow run if I don\u2019t specify an attribute in the WDL\u2019s input JSON?\u201d","sidebar":"docsSidebar"},"Best_practices/suggested_formats":{"id":"Best_practices/suggested_formats","title":"WDL formatting tips","description":"There are multiple WDL resources on how to keep scripts clean and easy to read. The Broad Pipeline Development team suggests checking out the BioWDL style guide for tips and tricks. The team follows most of the BioWDL guidelines, with a few exceptions and additions detailed in the table below:","sidebar":"docsSidebar"},"Best_practices/task_execution":{"id":"Best_practices/task_execution","title":"Task execution - tips for using the WDL task command section","description":"Every WDL task has a command section where you can call software tools and specify parameters to help transform your data into meaningful output. This section is like a terminal for whatever environment you\u2019re using to execute your WDL script. That environment can be a virtual computer set up by a Docker container or it can be your local computer. If you\u2019re using Cromwell to execute your WDL (as happens in the cloud-based platform Terra), the command section is run after Cromwell has resolved the task inputs but before it assesses outputs.","sidebar":"docsSidebar"},"contribution/contribute_to_warp_docs/doc_style":{"id":"contribution/contribute_to_warp_docs/doc_style","title":"Documentation Style Guide","description":"This guide provides some examples about how to add new documentation that can be properly rendered on this website. Please note most of the Github flavored Markdown syntax should work naturally, this guide just tries to elaborate the extension syntax to it.","sidebar":"docsSidebar"},"contribution/contribute_to_warp_docs/docsite_maintenance":{"id":"contribution/contribute_to_warp_docs/docsite_maintenance","title":"WARP Documentation Maintenance Guide","description":"This documentation site is built on top of the React-based  framework Docusaurus, so most of the recommended configuration can be found in the frameworks documentation.","sidebar":"docsSidebar"},"contribution/contribute_to_warp/changelog_style":{"id":"contribution/contribute_to_warp/changelog_style","title":"Changelog Style Guide Overview","description":"The style guide provides formatting guidelines and language suggestions for pipeline changelogs. It is divided into four sections: 1) Changelog Information, which details the types of changes listed in a changelog, 2) Language Usage, which describes language style and syntax for changelog information, 3) Changelog Format, which provides sample formatting for changelog information, and 4) Sample Changelog Entries, which displays two examples of changelog entries taken from the Optimus.changelog.md file.","sidebar":"docsSidebar"},"contribution/contribute_to_warp/contribution-guidelines":{"id":"contribution/contribute_to_warp/contribution-guidelines","title":"Contributing to Existing Pipelines","description":"We encourage the community to make contributions to our existing pipelines, such as updates to workflow code, Docker images and code, and accompanying documentation.","sidebar":"docsSidebar"},"contribution/contribute_to_warp/contribution-tutorial":{"id":"contribution/contribute_to_warp/contribution-tutorial","title":"Example Contribution","description":"Step-by-step instructions for a small pipeline update","sidebar":"docsSidebar"},"contribution/contribute_to_warp/wdl_task_runtime_style":{"id":"contribution/contribute_to_warp/wdl_task_runtime_style","title":"WDL Task Runtime Style Guide Overview","description":"This style guide provides formatting guidelines and best practices for the runtime block of a WDL workflow task. For more information about scripting in WDL, see the WDL 1.0 Specification.","sidebar":"docsSidebar"},"contribution/README":{"id":"contribution/README","title":"Welcome","description":"Welcome to WARP! We really appreciate your contribution! Please take some time to read the contribution guides before editing pages in GitHub.","sidebar":"docsSidebar"},"Deprecated_Pipelines/CEMBA_MethylC_Seq_Pipeline/CEMBA.methods":{"id":"Deprecated_Pipelines/CEMBA_MethylC_Seq_Pipeline/CEMBA.methods","title":"CEMBA_v1.1.6 Publication Methods","description":"Below we provide a sample methods section for a publication. For the complete pipeline documentation, see the CEMBA README.","sidebar":"docsSidebar"},"Deprecated_Pipelines/CEMBA_MethylC_Seq_Pipeline/README":{"id":"Deprecated_Pipelines/CEMBA_MethylC_Seq_Pipeline/README","title":"CEMBA Overview","description":"10/16/2024","sidebar":"docsSidebar"},"Deprecated_Pipelines/Genomic_Data_Commons_Whole_Genome_Somatic/README":{"id":"Deprecated_Pipelines/Genomic_Data_Commons_Whole_Genome_Somatic/README","title":"Genomic Data Commons (GDC) Whole Genome Somatic Single Sample Overview","description":"9/12/2014","sidebar":"docsSidebar"},"Deprecated_Pipelines/Single_Cell_ATAC_Seq_Pipeline/README":{"id":"Deprecated_Pipelines/Single_Cell_ATAC_Seq_Pipeline/README","title":"scATAC Overview","description":"9/12/2024","sidebar":"docsSidebar"},"Deprecated_Pipelines/Single_Cell_ATAC_Seq_Pipeline/scatac.methods":{"id":"Deprecated_Pipelines/Single_Cell_ATAC_Seq_Pipeline/scatac.methods","title":"scATAC v1.3.2 Methods","description":"Below we provide a sample methods section for a publication. For the complete pipeline documentation, see the scATAC Overview.","sidebar":"docsSidebar"},"Deprecated_Pipelines/Smart-seq2_Multi_Sample_Pipeline/Loom_schema":{"id":"Deprecated_Pipelines/Smart-seq2_Multi_Sample_Pipeline/Loom_schema","title":"What\'s in the Smart-seq2 Multi Sample Pipeline Loom File?","description":"The Loom is the Smart-seq2 Multi Sample pipeline\'s default cell-by-gene matrix. It is an HDF5 file generated using Loompy v.3.0.6 that is an aggregate of the individual output Loom files from the Smart-seq2 Single Sample pipeline.","sidebar":"docsSidebar"},"Deprecated_Pipelines/Smart-seq2_Multi_Sample_Pipeline/README":{"id":"Deprecated_Pipelines/Smart-seq2_Multi_Sample_Pipeline/README","title":"Smart-seq2 Multi-Sample Overview","description":"9/12/2014","sidebar":"docsSidebar"},"Deprecated_Pipelines/Smart-seq2_Multi_Sample_Pipeline/smart-seq2.methods":{"id":"Deprecated_Pipelines/Smart-seq2_Multi_Sample_Pipeline/smart-seq2.methods","title":"Smart-seq2 Multi-Sample v2.2.21 Publication Methods","description":"Below we provide an example methods section for a publication. For the complete pipeline documentation, see the Smart-seq2 Multi-Sample Overview.","sidebar":"docsSidebar"},"Deprecated_Pipelines/Smart-seq2_Single_Sample_Pipeline/Loom_schema":{"id":"Deprecated_Pipelines/Smart-seq2_Single_Sample_Pipeline/Loom_schema","title":"What\'s in the Smart-seq2 Single Sample Pipeline Loom File?","description":"The Loom file is an HDF5 file generated using Loompy v.3.0.6. It contains global attributes describing the Loom file and workflow that generated it (Table 1), column attributes detailing metrics for the individual cells (Table 2) and row attributes detailing metrics for individual genes (Table 3). The main matrix contains the RSEM TPMs and there is an additional layer that contains RSEM expectedcounts (the named \\"estimatedcounts\\").","sidebar":"docsSidebar"},"Deprecated_Pipelines/Smart-seq2_Single_Sample_Pipeline/README":{"id":"Deprecated_Pipelines/Smart-seq2_Single_Sample_Pipeline/README","title":"Smart-seq2 Single Sample Overview","description":"9/12/2014","sidebar":"docsSidebar"},"get-started":{"id":"get-started","title":"Welcome to WARP","description":"The Warp Analysis Research Pipelines repository is a collection of cloud-optimized pipelines for processing biological data from the Broad Institute Data Sciences Platform and collaborators.","sidebar":"docsSidebar"},"Pipelines/ATAC/atac.methods":{"id":"Pipelines/ATAC/atac.methods","title":"ATAC v2.3.1 Methods","description":"Data preprocessing and analysis for 10x chromatin accessibility was performed using the ATAC workflow v2.3.1 (RRIDZ tag. The resulting BAM was then processed with SnapATAC2 v2.7.0 to produce a fragment file, index, and h5ad containing fragments as well as per-barcode quality metrics.","sidebar":"docsSidebar"},"Pipelines/ATAC/count-matrix-overview":{"id":"Pipelines/ATAC/count-matrix-overview","title":"ATAC Count Matrix Overview","description":"The ATAC pipeline\'s default count matrix output is an h5ad file generated using SnapATAC2 and AnnData.","sidebar":"docsSidebar"},"Pipelines/ATAC/library-metrics":{"id":"Pipelines/ATAC/library-metrics","title":"ATAC Library Metrics Overview","description":"The ATAC pipeline uses SnapATAC2 to generate library-level metrics in CSV format.","sidebar":"docsSidebar"},"Pipelines/ATAC/README":{"id":"Pipelines/ATAC/README","title":"ATAC Overview","description":"| Pipeline Version | Date Updated | Documentation Author | Questions or Feedback |","sidebar":"docsSidebar"},"Pipelines/BuildIndices_Pipeline/README":{"id":"Pipelines/BuildIndices_Pipeline/README","title":"BuildIndices Overview","description":"| Pipeline Version | Date Updated | Documentation Author | Questions or Feedback |","sidebar":"docsSidebar"},"Pipelines/BuildIndices_Pipeline/ReferencesSpecies":{"id":"Pipelines/BuildIndices_Pipeline/ReferencesSpecies","title":"Reference Species","description":"The following table lists species for which reference files have been built or are in development using the BuildIndices pipeline. For more detailed information about each species and the links to the reference fies, please see the BuildIndices pipeline page.","sidebar":"docsSidebar"},"Pipelines/Exome_Germline_Single_Sample_Pipeline/exome.methods":{"id":"Pipelines/Exome_Germline_Single_Sample_Pipeline/exome.methods","title":"Exome Germline Single Sample v3.1.19 Methods","description":"The following contains a detailed methods description outlining the pipeline\u2019s process, software, and tools that can be modified for a publication methods section.","sidebar":"docsSidebar"},"Pipelines/Exome_Germline_Single_Sample_Pipeline/README":{"id":"Pipelines/Exome_Germline_Single_Sample_Pipeline/README","title":"Exome Germline Single Sample Overview","description":"| Pipeline Version | Date Updated | Documentation Author | Questions or Feedback |","sidebar":"docsSidebar"},"Pipelines/Illumina_Genotyping_Arrays_Pipeline/Illumina_genotyping_array_spec":{"id":"Pipelines/Illumina_Genotyping_Arrays_Pipeline/Illumina_genotyping_array_spec","title":"VCF Overview: Illumina Genotyping Array","description":"The Illumina Genotyping Array Pipeline v1.12.17 pipeline produces a VCF (Variant Call Format) output with data processing and sample-specific genotype information. The VCF follows the format listed in the VCF 4.2 specification, but additionally contains fields and attributes that are unique to the Arrays pipeline.","sidebar":"docsSidebar"},"Pipelines/Illumina_Genotyping_Arrays_Pipeline/README":{"id":"Pipelines/Illumina_Genotyping_Arrays_Pipeline/README","title":"Illumina Genotyping Array Overview","description":"| Pipeline Version | Date Updated | Documentation Author | Questions or Feedback |","sidebar":"docsSidebar"},"Pipelines/Imputation_Pipeline/README":{"id":"Pipelines/Imputation_Pipeline/README","title":"Imputation Overview","description":"| Pipeline Version | Date Updated | Documentation Author | Questions or Feedback |","sidebar":"docsSidebar"},"Pipelines/Imputation_Pipeline/references_overview":{"id":"Pipelines/Imputation_Pipeline/references_overview","title":"Creating the Imputation Pipeline\'s Modified 1000 Genomes Reference","description":"Background","sidebar":"docsSidebar"},"Pipelines/ImputationBeagle_Pipeline/README":{"id":"Pipelines/ImputationBeagle_Pipeline/README","title":"Imputation Overview","description":"|                                                  Pipeline Version                                                  | Date Updated |        Documentation Author        |                             Questions or Feedback                              |","sidebar":"docsSidebar"},"Pipelines/JointGenotyping/README":{"id":"Pipelines/JointGenotyping/README","title":"JointGenotyping Overview","description":"| Pipeline Version | Date Updated | Documentation Author | Questions or Feedback |","sidebar":"docsSidebar"},"Pipelines/Multiome_Pipeline/README":{"id":"Pipelines/Multiome_Pipeline/README","title":"Multiome Overview","description":"| Pipeline Version | Date Updated | Documentation Author | Questions or Feedback |","sidebar":"docsSidebar"},"Pipelines/Optimus_Pipeline/Bam_tags":{"id":"Pipelines/Optimus_Pipeline/Bam_tags","title":"What tags are included in an Optimus BAM file?","description":"The Optimus Pipeline outputs a barcoded BAM file of aligned reads. There are multiple tags within the BAM file, including standard tags from 10X genomics and Sequence Alignment Map (SAM) files. The table below details the tags used by the Optimus Pipeline and the relevant sources/tools from which the pipeline obtains the tags.","sidebar":"docsSidebar"},"Pipelines/Optimus_Pipeline/consortia-processing":{"id":"Pipelines/Optimus_Pipeline/consortia-processing","title":"Consortia Data Processing","description":"Human Cell Atlas Data Coordination Platform Matrix Processing","sidebar":"docsSidebar"},"Pipelines/Optimus_Pipeline/Library-metrics":{"id":"Pipelines/Optimus_Pipeline/Library-metrics","title":"Optimus Library-level metrics","description":"The following table describes the library level metrics of the produced by the Optimus workflow. These are calcuated using custom python scripts available in the warp-tools repository. The Optimus workflow aligns files in shards to parallelize computationally intensive steps. This results in multiple matrix market files and shard-level library metrics.","sidebar":"docsSidebar"},"Pipelines/Optimus_Pipeline/Loom_schema":{"id":"Pipelines/Optimus_Pipeline/Loom_schema","title":"Optimus Count Matrix Overview","description":"The Loom matrix is deprecated and the default matrix is now h5ad.","sidebar":"docsSidebar"},"Pipelines/Optimus_Pipeline/optimus.methods":{"id":"Pipelines/Optimus_Pipeline/optimus.methods","title":"Optimus v7.8.1 Methods","description":"Below we provide an example methods section for a publication, separated into single-cell or single-nucleus use cases. For the complete pipeline documentation, see the Optimus Overview.","sidebar":"docsSidebar"},"Pipelines/Optimus_Pipeline/README":{"id":"Pipelines/Optimus_Pipeline/README","title":"Optimus Overview","description":"| Pipeline Version | Date Updated | Documentation Author | Questions or Feedback |","sidebar":"docsSidebar"},"Pipelines/Optimus_Pipeline/starsolo-metrics":{"id":"Pipelines/Optimus_Pipeline/starsolo-metrics","title":"STAR Aligner Metrics","description":"The STAR aligner produces multiple text files containing library-level summary metrics, cell-level metrics, and UMI metrics. The Optimus workflow compresses these files into a single TAR. These outputs are directly from the aligner as different batches of the data are analyzed in parallel.","sidebar":"docsSidebar"},"Pipelines/PairedTag_Pipeline/README":{"id":"Pipelines/PairedTag_Pipeline/README","title":"Paired-Tag Overview","description":"|                          Pipeline Version                           | Date Updated | Documentation Author | Questions or Feedback |","sidebar":"docsSidebar"},"Pipelines/RNA_with_UMIs_Pipeline/README":{"id":"Pipelines/RNA_with_UMIs_Pipeline/README","title":"RNA with UMIs Overview","description":"| Pipeline Version | Date Updated | Documentation Authors | Questions or Feedback |","sidebar":"docsSidebar"},"Pipelines/RNA_with_UMIs_Pipeline/rna-with-umis.methods":{"id":"Pipelines/RNA_with_UMIs_Pipeline/rna-with-umis.methods","title":"RNA with UMIs v1.0.16 Methods","description":"Below we provide an example methods section for publications using the RNA with UMIs pipeline. For the complete pipeline documentation, see the RNA with UMIs Overview.","sidebar":"docsSidebar"},"Pipelines/SlideSeq_Pipeline/count-matrix-overview":{"id":"Pipelines/SlideSeq_Pipeline/count-matrix-overview","title":"Slide-seq Count Matrix Overview","description":"The Loom matrix is deprecated and the default matrix is now h5ad.","sidebar":"docsSidebar"},"Pipelines/SlideSeq_Pipeline/README":{"id":"Pipelines/SlideSeq_Pipeline/README","title":"Slide-seq Overview","description":"| Pipeline Version | Date Updated | Documentation Author | Questions or Feedback |","sidebar":"docsSidebar"},"Pipelines/SlideTags_Pipeline/README":{"id":"Pipelines/SlideTags_Pipeline/README","title":"Slide-tags Overview","description":"| Pipeline Version | Date Updated | Documentation Author | Questions or Feedback |","sidebar":"docsSidebar"},"Pipelines/Smart-seq2_Single_Nucleus_Multi_Sample_Pipeline/consortia-processing":{"id":"Pipelines/Smart-seq2_Single_Nucleus_Multi_Sample_Pipeline/consortia-processing","title":"Consortia Data Processing","description":"Brain Initiative Cell Census Network Processing","sidebar":"docsSidebar"},"Pipelines/Smart-seq2_Single_Nucleus_Multi_Sample_Pipeline/count-matrix-overview":{"id":"Pipelines/Smart-seq2_Single_Nucleus_Multi_Sample_Pipeline/count-matrix-overview","title":"Smart-seq2 Single Nucleus Multi-Sample Count Matrix Overview","description":"The Smart-seq2 Single Nucleus Multi-Sample (Multi-snSS2) pipeline\'s default count matrix output is a Loom file, an HDF5 file generated using Loompy v.3.0.6. It contains the raw cell-by-gene intron and exon counts.","sidebar":"docsSidebar"},"Pipelines/Smart-seq2_Single_Nucleus_Multi_Sample_Pipeline/multi_snss2.methods":{"id":"Pipelines/Smart-seq2_Single_Nucleus_Multi_Sample_Pipeline/multi_snss2.methods","title":"Smart-seq2 Single Nucleus Multi-Sample v1.3.4 Publication Methods","description":"Below we provide an example methods section for a publication. For the complete pipeline documentation, see the Smart-seq2 Single Nucleus Multi-Sample Overview.","sidebar":"docsSidebar"},"Pipelines/Smart-seq2_Single_Nucleus_Multi_Sample_Pipeline/README":{"id":"Pipelines/Smart-seq2_Single_Nucleus_Multi_Sample_Pipeline/README","title":"Smart-seq2 Single Nucleus Multi-Sample Overview","description":"| Pipeline Version | Date Updated | Documentation Author | Questions or Feedback |","sidebar":"docsSidebar"},"Pipelines/snM3C/README":{"id":"Pipelines/snM3C/README","title":"Single Nucleus Methyl-Seq and Chromatin Capture (snm3C) Overview","description":"| Pipeline Version | Date Updated | Documentation Authors | Questions or Feedback |","sidebar":"docsSidebar"},"Pipelines/snM3C/snm3c.methods":{"id":"Pipelines/snM3C/snm3c.methods","title":"snM3C v4.0.1 Methods","description":"Methylome and chromatin contact sequencing data was preprocessed for downstream analysis using the snm3C v4.0.1 pipeline (RRID:SCR025041). Briefly, Cutadapt software was used to demultiplex paired-end sequencing reads from a single 384-well plate to cell-level FASTQ files based on a list of random primer indices, and then further used to sort, filter, and trim reads. Paired-end reads were then aligned to the human hg38 v43 reference genome using HISAT-3N. Custom python scripts from the CEMBA GitHub repository were then called to separate unmapped reads, unique reads, and multi-mapped reads. The unmapped reads were saved to a FASTQ file and used for single-end alignment with HISAT-3N. Overlapping reads were removed and all resulting aligned reads merged into a single BAM. All mapped reads were deduplicated using samtools and Picard. The resulting BAM was used as input to a custom CEMBA python script for chromatin contact calling based on a 2,500 base pair threshold and as input to the ALLCools software for methylation site calling. Key summary statistics for read trimming, mapping, deduplication and chromatin contacts were then calculated and exported to a summary metrics file.","sidebar":"docsSidebar"},"Pipelines/snM3C/summary_metrics":{"id":"Pipelines/snM3C/summary_metrics","title":"snm3C Mapping Summary Metrics Overview","description":"The snm3C pipeline outputs a summary CSV file containing trimming, mapping, deduplication, chromatin contact, and ALLC site statistics.","sidebar":"docsSidebar"},"Pipelines/Ultima_Genomics_Whole_Genome_Germline_Pipeline/README":{"id":"Pipelines/Ultima_Genomics_Whole_Genome_Germline_Pipeline/README","title":"Ultima Genomics Whole Genome Germline Overview","description":"| Pipeline Version | Date Updated | Documentation Authors | Questions or Feedback |","sidebar":"docsSidebar"},"Pipelines/Whole_Genome_Germline_Single_Sample_Pipeline/README":{"id":"Pipelines/Whole_Genome_Germline_Single_Sample_Pipeline/README","title":"Whole Genome Germline Single Sample Overview","description":"| Pipeline Version | Date Updated | Documentation Author | Questions or Feedback |","sidebar":"docsSidebar"},"Pipelines/Whole_Genome_Germline_Single_Sample_Pipeline/wgs.methods":{"id":"Pipelines/Whole_Genome_Germline_Single_Sample_Pipeline/wgs.methods","title":"Whole Genome Germline Single Sample v3.1.20 Methods (Default workflow)","description":"The following contains a detailed methods description outlining the pipeline\u2019s process, software, and tools that can be modified for a publication methods section.","sidebar":"docsSidebar"}}}')}}]);