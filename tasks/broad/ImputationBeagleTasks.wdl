version 1.0

task CountVariantsInChunks {
  input {
    File vcf
    File vcf_index
    File panel_bed_file

    String gatk_docker = "us.gcr.io/broad-gatk/gatk:4.5.0.0"
    Int cpu = 1
    Int memory_mb = 16000
    Int disk_size_gb = 2 * ceil(size([vcf, vcf_index, panel_bed_file], "GiB")) + 10
  }
  Int command_mem = memory_mb - 1500
  Int max_heap = memory_mb - 1000

  command <<<
    set -e -o pipefail

    ln -sf ~{vcf} input.vcf.gz
    ln -sf ~{vcf_index} input.vcf.gz.tbi

    gatk --java-options "-Xms~{command_mem}m -Xmx~{max_heap}m" CountVariants -V input.vcf.gz | tail -n 1 > var_in_original
    bedtools intersect -a ~{vcf} -b ~{panel_bed_file} | wc -l > var_also_in_reference
  >>>

  output {
    Int var_in_original = read_int("var_in_original")
    Int var_also_in_reference = read_int("var_also_in_reference")
  }
  runtime {
    docker: gatk_docker
    disks: "local-disk ${disk_size_gb} HDD"
    memory: "${memory_mb} MiB"
    cpu: cpu
    preemptible: 3
    maxRetries: 2
    noAddress: true
  }
}

task CheckChunks {
  input {
    Int var_in_original
    Int var_also_in_reference

    String bcftools_docker = "us.gcr.io/broad-gotc-prod/imputation-bcf-vcf:1.0.7-1.10.2-0.1.16-1669908889"
    Int cpu = 1
    Int memory_mb = 4000
  }
  command <<<
    set -e -o pipefail

    if [ $(( ~{var_also_in_reference} * 2 - ~{var_in_original})) -gt 0 ] && [ ~{var_also_in_reference} -gt 3 ]; then
      echo true > valid_file.txt
    else
      echo false > valid_file.txt
    fi
  >>>
  output {
    Boolean valid = read_boolean("valid_file.txt")
  }
  runtime {
    docker: bcftools_docker
    disks: "local-disk 10 HDD"
    memory: "${memory_mb} MiB"
    cpu: cpu
    preemptible: 3
    maxRetries: 2
    noAddress: true
  }
}

task Phase {
  input {
    File dataset_vcf
    File ref_panel_bref3
    File genetic_map_file
    String basename
    String chrom
    Int start
    Int end

    String beagle_docker = "us.gcr.io/broad-gotc-prod/imputation-beagle:1.0.0-17Dec24.224-1740423035"
    Int cpu = 8                    # This parameter is used as the nthreads input to Beagle which is part of how we make it determinstic.  Changing this value may change the output generated by the tool
    Int memory_mb = 32000          # value depends on chunk size, the number of samples in ref and target panel, and whether imputation is performed
    Int xmx_mb = memory_mb - 5000             # I suggest setting this parameter to be 85-90% of the memory_mb parameter
    Int disk_size_gb = ceil(3 * size([dataset_vcf, ref_panel_bref3], "GiB")) + 10         # value may need to be adjusted

    Boolean for_dependency         # used for task dependency management
  }

  command <<<
    set -e -o pipefail

    java -ea -Xmx~{xmx_mb}m \
    -jar /usr/gitc/beagle.17Dec24.224.jar \
    gt=~{dataset_vcf} \
    ref=~{ref_panel_bref3} \
    map=~{genetic_map_file} \
    out=phased_~{basename} \
    chrom=~{chrom}:~{start}-~{end} \
    impute=false \
    nthreads=~{cpu} \
    seed=-99999

  >>>
  output {
    File vcf = "phased_~{basename}.vcf.gz"
    File log = "phased_~{basename}.log"
  }
  runtime {
    docker: beagle_docker
    disks: "local-disk ${disk_size_gb} HDD"
    memory: "${memory_mb} MiB"
    cpu: cpu
    preemptible: 3
    maxRetries: 2
    noAddress: true
  }
}

task Impute {
  input {
    File dataset_vcf
    File ref_panel_bref3
    File genetic_map_file
    String basename
    String chrom
    Int start
    Int end
    Boolean impute_with_allele_probabilities

    String beagle_docker = "us.gcr.io/broad-gotc-prod/imputation-beagle:1.0.0-17Dec24.224-1740423035"
    Int cpu = 8                    # This parameter is used as the nthreads input to Beagle which is part of how we make it determinstic.  Changing this value may change the output generated by the tool
    Int memory_mb = 32000          # value depends on chunk size, the number of samples in ref and target panel, and whether imputation is performed
    Int xmx_mb = memory_mb - 5000             # I suggest setting this parameter to be 85-90% of the memory_mb parameter
    Int disk_size_gb = ceil(3 * size([dataset_vcf, ref_panel_bref3], "GiB")) + 10         # value may need to be adjusted
  }

  command <<<
    set -e -o pipefail

    java -ea -Xmx~{xmx_mb}m \
    -jar /usr/gitc/beagle.17Dec24.224.jar \
    gt=~{dataset_vcf} \
    ref=~{ref_panel_bref3} \
    map=~{genetic_map_file} \
    out=imputed_~{basename} \
    chrom=~{chrom}:~{start}-~{end} \
    impute=true \
    ~{if impute_with_allele_probabilities then "ap=true" else ""} \
    nthreads=~{cpu} \
    seed=-99999

  >>>
  output {
    File vcf = "imputed_~{basename}.vcf.gz"
    File log = "imputed_~{basename}.log"
  }
  runtime {
    docker: beagle_docker
    disks: "local-disk ${disk_size_gb} HDD"
    memory: "${memory_mb} MiB"
    cpu: cpu
    preemptible: 3
    maxRetries: 2
    noAddress: true
  }
}

task ErrorWithMessageIfErrorCountNotZero {
  input {
    Int errorCount
    String message
  }
  command <<<
    if [[ ~{errorCount} -gt 0 ]]; then
      >&2 echo "Error: ~{message}"
      exit 1
    else
      exit 0
    fi
  >>>

  runtime {
    docker: "us.gcr.io/broad-dsde-methods/ubuntu:20.04"
    preemptible: 3
    maxRetries: 2
    noAddress: true
  }
  output {
    Boolean done = true
  }
}

task CreateVcfIndex {
  input {
    File vcf_input

    Int disk_size_gb = ceil(1.2*size(vcf_input, "GiB")) + 10
    Int cpu = 1
    Int memory_mb = 6000
    String gatk_docker = "us.gcr.io/broad-gatk/gatk:4.5.0.0"
  }
  Int command_mem = memory_mb - 1500
  Int max_heap = memory_mb - 1000

  String vcf_basename = basename(vcf_input)

  command {
    set -e -o pipefail

    ln -sf ~{vcf_input} ~{vcf_basename}

    bcftools index -t ~{vcf_basename}
  }
  runtime {
    docker: gatk_docker
    disks: "local-disk ${disk_size_gb} HDD"
    memory: "${memory_mb} MiB"
    cpu: cpu
    preemptible: 3
    maxRetries: 2
    noAddress: true
  }
  output {
    File vcf = "~{vcf_basename}"
    File vcf_index = "~{vcf_basename}.tbi"
  }
}

task LocalizeAndSubsetVcfToRegion {
  input {
    File vcf
    String output_basename
    String contig
    Int start
    Int end
    Boolean exclude_filtered = false

    Int disk_size_gb = ceil(2*size(vcf, "GiB")) + 10
    Int cpu = 1
    Int memory_mb = 6000
    String gatk_docker = "us.gcr.io/broad-gatk/gatk:4.6.1.0"
  }
  Int command_mem = memory_mb - 1500
  Int max_heap = memory_mb - 1000

  command {
    set -e -o pipefail

    tabix ~{vcf}

    gatk --java-options "-Xms~{command_mem}m -Xmx~{max_heap}m" \
    SelectVariants \
    -V ~{vcf} \
    -L ~{contig}:~{start}-~{end} \
    -select 'POS >= ~{start}' ~{if exclude_filtered then "--exclude-filtered" else ""} \
    -O ~{output_basename}.vcf.gz
  }

  runtime {
    docker: gatk_docker
    disks: "local-disk ${disk_size_gb} HDD"
    memory: "${memory_mb} MiB"
    cpu: cpu
    preemptible: 3
    maxRetries: 2
    noAddress: true
  }

  output {
    File output_vcf = "~{output_basename}.vcf.gz"
    File output_vcf_index = "~{output_basename}.vcf.gz.tbi"
  }
}

task SelectSamplesWithCut {
  input {
    File vcf

    Int cut_start_field
    Int cut_end_field
    String basename

    Int disk_size_gb = ceil(1.5 * size(vcf, "GiB")) + 10
    String bcftools_docker = "us.gcr.io/broad-gotc-prod/imputation-bcf-vcf:1.0.7-1.10.2-0.1.16-1669908889"
    Int cpu = 2
    Int memory_mb = 6000
  }

  command <<<
    set -euo pipefail

    mkfifo fifo_bgzip
    mkfifo fifo_cut

    bcftools view -h --no-version ~{vcf} | awk '!/^#CHROM/' > header.vcf
    n_lines=$(wc -l header.vcf | cut -d' ' -f1)

    cat header.vcf
    echo $n_lines

    bgzip -d ~{vcf} -o fifo_bgzip &
    tail +$((n_lines)) fifo_bgzip | cut -f 1-9,~{cut_start_field}-~{cut_end_field} > fifo_cut &

    cat header.vcf fifo_cut | bgzip -o ~{basename}.vcf.gz
  >>>

  runtime {
    docker: "us.gcr.io/broad-dsde-methods/ckachulis/bcftools_bgzip"
    disks: "local-disk " + disk_size_gb + " HDD"
    memory: memory_mb + " MiB"
    preemptible: 3
    maxRetries: 2
    noAddress: true
    cpu: cpu
  }

  output {
    File output_vcf = "~{basename}.vcf.gz"
  }
}

task MergeSampleChunksVcfsWithPaste {
  input {
    Array[File] input_vcfs
    String output_vcf_basename

    Int disk_size_gb = ceil(2.2 * size(input_vcfs, "GiB") + 50)
    Int mem_gb = 12
    Int cpu = 4
    Int preemptible = 3
  }

  command <<<
    set -euo pipefail

    vcfs=(~{sep=" " input_vcfs})

    mkfifo fifo_0
    mkfifo fifo_to_paste_0

    i=1

    fifos_to_paste=()
    md5sums=()
    bcftools view -h --no-version ${vcfs[0]} | awk '!/^#CHROM/' > header.vcf
    n_lines=$(wc -l header.vcf | cut -d' ' -f1)

    bgzip -d ${vcfs[0]} -o fifo_0 &

    tail +$((n_lines)) fifo_0 | tee fifo_to_paste_0 | cut -f1-5,9 | md5sum > md5sum_0 &

    for vcf in "${vcfs[@]:1}"; do
      fifo_name="fifo_$i"
      mkfifo "$fifo_name"

      fifo_name_to_md5="fifo_to_md5_$i"
      mkfifo "$fifo_name_to_md5"

      fifo_name_to_paste="fifo_to_paste_$i"
      mkfifo "$fifo_name_to_paste"
      fifos_to_paste+=("$fifo_name_to_paste")

      file_name_md5sum="md5sum_$i"
      md5sums+=("$file_name_md5sum")
      n_lines=$(bcftools view -h --no-version $vcf | awk '!/^#CHROM/' | wc -l | cut -d' ' -f1)

      bgzip -d ${vcf} -o "$fifo_name" &
      tail +$((n_lines)) "$fifo_name" | tee "$fifo_name_to_md5" | cut -f 10- > "$fifo_name_to_paste" &
      cut -f1-5,9 "$fifo_name_to_md5" | md5sum > "$file_name_md5sum" &

      ((i++))
    done

    mkfifo fifo_to_cat

    paste fifo_to_paste_0 "${fifos_to_paste[@]}" | tee fifo_to_cat | awk 'NR % 5000000 == 0' | cut -f 1-5 &


    cat header.vcf fifo_to_cat | bgzip -o ~{output_vcf_basename}.vcf.gz

    for md5sum_file in "${md5sums[@]}"; do
    diff <(cat md5sum_0) <(cat $md5sum_file) >> /dev/null || (echo "Fields 1-5,9 do not match for $md5sum_file" && exit 1)
    done

    for fifo in fifo_*; do
    rm $fifo
    done

  >>>

  runtime {
    docker: "us.gcr.io/broad-dsde-methods/ckachulis/bcftools_bgzip@sha256:6035c38fbc4b8631af796a99c568253f2c26886a97c5fd42ce4b8355f424307d"
    disks: "local-disk " + disk_size_gb + " HDD"
    memory: mem_gb + " GiB"
    cpu: cpu
    preemptible: preemptible
    maxRetries: 2
    noAddress: true
  }

  output {
    File output_vcf = "~{output_vcf_basename}.vcf.gz"
  }
}

task QueryMergedVcfForReannotation {
  input {
    File vcf
    Int disk_size_gb = ceil(2 * size(vcf, "GiB")) + 10
    Int mem_gb = 4
    Int cpu = 1
    Int preemptible = 3
  }
  String vcf_basename = basename(vcf)

  command <<<
    set -euo pipefail
    ln -sf ~{vcf} ~{vcf_basename}

    tabix ~{vcf_basename}

    bcftools query -f '%CHROM,%POS,%REF,%ALT[,%DS,%AP1,%AP2]\n' ~{vcf} | gzip -c > query_tbl.csv.gz
  >>>


  runtime {
    docker: "us.gcr.io/broad-dsde-methods/samtools-suite:v1.1"
    disks: "local-disk " + disk_size_gb + " HDD"
    memory: mem_gb + " GiB"
    cpu: cpu
    preemptible: preemptible
    maxRetries: 2
    noAddress: true
  }

  output {
    File output_query_file = "query_tbl.csv.gz"
    File output_vcf = "~{vcf_basename}"
    File output_vcf_index = "~{vcf_basename}.tbi"
  }
}

task RecalculateDR2AndAF {
  input {
    File query_file
    Int n_samples
    Int disk_size_gb = ceil(2 * size(query_file, "GiB")) + 10
    Int mem_gb = 4
    Int cpu = 1
    Int chunksize = 10000
    Int preemptible = 3
  }

  command <<<
    set -euo pipefail

    python3 << EOF
    import pandas as pd
    import numpy as np

    ds_dict = {f'sample_{i}_DS': 'float' for i in range(~{n_samples})}
    ap1_dict = {f'sample_{i}_AP1': 'float' for i in range(~{n_samples})}
    ap2_dict = {f'sample_{i}_AP2': 'float' for i in range(~{n_samples})}
    dtypes_dict = {**ds_dict, **ap1_dict, **ap2_dict}

    csv_names = ["CHROM","POS","REF","ALT"] + [f'sample_{i}_{col}' for i in range(~{n_samples}) for col in ("DS", "AP1", "AP2")]

    out_annotation_dfs = []
    for chunk in pd.read_csv("~{query_file}", names=csv_names, dtype=dtypes_dict, na_values=".", chunksize = ~{chunksize}, lineterminator="\n"):
      # get sample level annotaions necessary for AF and DR2 calculations
      dosages = chunk[[f'sample_{i}_DS' for i in range(~{n_samples})]].to_numpy()
      ap1 = chunk[[f'sample_{i}_AP1' for i in range(~{n_samples})]].to_numpy()
      ap2 = chunk[[f'sample_{i}_AP2' for i in range(~{n_samples})]].to_numpy()

      # AF calc
      af = dosages.mean(axis=1)/2
      af_rounded = np.round(af, 4)

      # DR2 calc
      sum_squared_ap1_ap2 = np.sum(ap1**2 + ap2**2, axis=1)
      sum_ap1_ap2 = np.sum(ap1 + ap2, axis=1)
      denominator = (2*~{n_samples} * sum_ap1_ap2) - (sum_ap1_ap2**2)

      # values to annotate the vcf with
      chunk_annotations = chunk[["CHROM","POS","REF","ALT"]]
      chunk_annotations["AF"] = af_rounded
      chunk_annotations["DR2"] = np.where((af==0) | (af==1) | (denominator==0), 0.00, np.round(((2*~{n_samples} * sum_squared_ap1_ap2) - (sum_ap1_ap2**2)) / denominator, 2))
      out_annotation_dfs.append(chunk_annotations)

    annotations_df = pd.concat(out_annotation_dfs)
    annotations_df.to_csv("annotations.tsv", sep="\t", index=False, header=False)
    EOF

    echo "$(date) - annotations recomputed"

    bgzip annotations.tsv
    tabix -s1 -b2 -e2 annotations.tsv.gz

  >>>

  runtime {
    docker: "us.gcr.io/broad-dsde-methods/samtools-suite:v1.1"
    disks: "local-disk " + disk_size_gb + " HDD"
    memory: mem_gb + " GiB"
    cpu: cpu
    preemptible: preemptible
    maxRetries: 2
    noAddress: true
  }

  output {
    File output_annotations_file = "annotations.tsv.gz"
    File output_annotations_file_index = "annotations.tsv.gz.tbi"
  }
}


task ReannotateDR2AndAF {
  input {
    File vcf
    File vcf_index
    File annotations_tsv
    File annotations_tsv_index
    Int disk_size_gb = ceil(2 * size(vcf, "GiB") + size(annotations_tsv, "GiB")) + 10
    Int mem_gb = 4
    Int cpu = 1
    Int preemptible = 3
  }

  String output_base = basename(vcf, ".vcf.gz")

  command <<<
    set -euo pipefail

    echo "$(date) - annotating vcf with new annotations"
    bcftools annotate --no-version -a ~{annotations_tsv} -c CHROM,POS,REF,ALT,AF,DR2 -x FORMAT/AP1,FORMAT/AP2 -Oz -o ~{output_base}.vcf.gz ~{vcf}

    echo "$(date) - indexing annotated vcf"
    bcftools index -t ~{output_base}.vcf.gz
  >>>


  runtime {
    docker: "us.gcr.io/broad-dsde-methods/samtools-suite:v1.1"
    disks: "local-disk " + disk_size_gb + " HDD"
    memory: mem_gb + " GiB"
    cpu: cpu
    preemptible: preemptible
    maxRetries: 2
    noAddress: true
  }

  output {
    File output_vcf = "~{output_base}.vcf.gz"
    File output_vcf_index = "~{output_base}.vcf.gz.tbi"
  }
}
